# ğŸ“Š RÃ©alisation dâ€™un Dashboard de Scoring CrÃ©dit & Veille Technique NLP

## ğŸ§© Description du projet
Ce projet combine deux volets complÃ©mentaires :

1. **DÃ©veloppement dâ€™un Dashboard interactif** de scoring crÃ©dit permettant une analyse explicable et dynamique des clients via **Streamlit** et une **API Flask** dÃ©ployÃ©e sur **Heroku**.
2. **Veille technique en NLP**, comparant les modÃ¨les **BERT-base-uncased** et **all-MiniLM-L6-v2** pour la classification de produits e-commerce Ã  partir de descriptions textuelles.

---

## ğŸ—ï¸ Structure du dÃ©pÃ´t
```text
realisation_dashboard_veille_technique/
â”‚
â”œâ”€â”€ Martineau_Alexandre_3_note_mÃ©thodologique_022025.pdf    # Note mÃ©thodologique - MiniLM vs BERT
â”œâ”€â”€ Martineau_Alexandre_4_presentation_022025.pdf           # PrÃ©sentation PowerPoint du projet
â”‚
â”œâ”€â”€ Martineau_Alexandre_1_dashboard_022025.py               # Script principal Streamlit
â”œâ”€â”€ Martineau_Alexandre_2_notebook_veille_022025.ipynb      # Notebook de veille technique NLP
â””â”€â”€ README.md
```

## ğŸ–¥ï¸ 1ï¸âƒ£ Dashboard de Scoring CrÃ©dit

### âš™ï¸ Objectif
Concevoir une interface interactive et explicable pour visualiser le **score de crÃ©dit**, la **probabilitÃ© de remboursement**, et les **caractÃ©ristiques influentes** dâ€™un client.

### ğŸ§° Technologies
- **Frontend / Dashboard** : Streamlit, Plotly, Seaborn, Matplotlib  
- **Backend / API** : Flask (API dÃ©ployÃ©e sur Heroku : [my-scoring-app](https://my-scoring-app-546acd78d8fa.herokuapp.com/))  
- **ML Explainability** : SHAP (global + local), Feature Engineering dynamique  
- **CI/CD & HÃ©bergement** : Heroku + GitHub Actions  

### ğŸ’¡ FonctionnalitÃ©s principales
- SÃ©lection dâ€™un client et affichage de son score de crÃ©dit.  
- Modification des informations via une **barre latÃ©rale interactive**.  
- Recalcul instantanÃ© du score et des valeurs SHAP.  
- Visualisation :
  - **Jauge dynamique** du score et du seuil dâ€™acceptabilitÃ© (52 %).  
  - **Importance globale et locale** des variables explicatives.  
  - **Analyses croisÃ©es** et **bi-variÃ©es** des variables.  

### ğŸ§  InterprÃ©tabilitÃ©
- **SHAP Global** : pondÃ©ration moyenne des features expliquant les dÃ©cisions du modÃ¨le.  
- **SHAP Local** : explication dâ€™une prÃ©diction individuelle.  
- **Visualisation dynamique** : beeswarm plots, waterfall plots, histograms et scatter plots interactifs.  

---

### ğŸ”— API utilisÃ©e
| Endpoint | Description |
|-----------|-------------|
| `/predict_proba` | PrÃ©diction du score de crÃ©dit |
| `/best_threshold` | Renvoie le seuil de dÃ©cision optimal |
| `/download_model` | TÃ©lÃ©chargement du modÃ¨le entraÃ®nÃ© |
| `/data` | PrÃ©paration et transformation des donnÃ©es dâ€™entrÃ©e |

---

## ğŸ§¬ 2ï¸âƒ£ Veille Technique : NLP & Classification de Produits

### ğŸ¯ Objectif
Comparer les performances de deux modÃ¨les NLP :
- **BERT-base-uncased** (modÃ¨le classique Hugging Face)
- **all-MiniLM-L6-v2** (modÃ¨le distillÃ©, 3Ã— plus rapide et 3Ã— plus lÃ©ger)

sur un **jeu de donnÃ©es Flipkart e-commerce**, afin dâ€™Ã©valuer leur efficacitÃ© pour la **classification de produits** selon leur description textuelle.

---

### ğŸ§© MÃ©thodologie
1. **PrÃ©traitement des donnÃ©es** : extraction des catÃ©gories principales, nettoyage des textes.  
2. **Encodage des descriptions** :
   - BERT via `TFAutoModel` (Hugging Face)  
   - MiniLM via `SentenceTransformer("all-MiniLM-L6-v2")`  
3. **Classification** :
   - ModÃ¨le : RÃ©gression Logistique  
   - Ã‰valuation : Accuracy + Classification Report  
4. **Visualisation** :
   - RÃ©duction de dimension via **t-SNE**  
   - Clustering via **KMeans**  
   - Calcul de lâ€™**ARI (Adjusted Rand Index)**  

---

### ğŸ“ˆ RÃ©sultats

| ModÃ¨le | Accuracy | ARI | Commentaire |
|---------|:--------:|:----:|-------------|
| **BERT-base-uncased** | 0.93 | 0.31 | Bonne sÃ©paration, clusters mÃ©langÃ©s |
| **all-MiniLM-L6-v2** | **0.95** | **0.71** | Excellente sÃ©paration, embeddings plus cohÃ©rents |

Les rÃ©sultats dÃ©montrent que **MiniLM** offre une **prÃ©cision Ã©quivalente Ã  BERT** tout en Ã©tant **plus lÃ©ger et plus rapide**, ce qui le rend particuliÃ¨rement adaptÃ© Ã  des contextes de production et de veille technique.

---

### ğŸ› ï¸ Technologies utilisÃ©es
- **Machine Learning** : scikit-learn, numpy, pandas  
- **NLP** : Hugging Face Transformers, Sentence-Transformers, TensorFlow  
- **Visualisation** : matplotlib, seaborn, Plotly  
- **Dashboard & API** : Streamlit, Flask, Heroku  
- **Explainability & Monitoring** : SHAP  

---

### ğŸ” RÃ©sumÃ© global du projet
Ce dÃ©pÃ´t illustre :
- Lâ€™intÃ©gration **MLOps + DataViz** via un dashboard explicable et dÃ©ployÃ©.  
- Une **veille NLP** approfondie comparant deux modÃ¨les de gÃ©nÃ©ration dâ€™embeddings modernes.  
- Une approche **complÃ¨te du cycle IA**, de la collecte de donnÃ©es Ã  lâ€™explicabilitÃ© en production.  

### ğŸ“¦ DÃ©pÃ´t & Ressources

ğŸ”— DÃ©pÃ´t GitHub : realisation_dashboard_veille_technique
ğŸ”— API Scoring : https://my-scoring-app-546acd78d8fa.herokuapp.com/

## âœ… Conclusion

Ce projet associe data science appliquÃ©e et veille technologique autour de deux axes :
- un dashboard explicable en production pour la prise de dÃ©cision en crÃ©dit,
- une analyse comparative de modÃ¨les NLP pour la classification de produits e-commerce.

Il dÃ©montre une maÃ®trise du cycle complet de la donnÃ©e Ã  la visualisation, intÃ©grant transparence, performance et innovation.
